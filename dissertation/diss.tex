% Template for a Computer Science Tripos Part II project dissertation
\documentclass[12pt,a4paper,twoside,openright]{report}
\usepackage[pdfborder={0 0 0}, breaklinks]{hyperref}    % turns references into hyperlinks
\usepackage[margin=25mm]{geometry}  % adjusts page layout
\usepackage{graphicx}  % allows inclusion of PDF, PNG and JPG images
\usepackage{docmute}   % only needed to allow inclusion of proposal.tex
\usepackage{listings}
\usepackage{tikz}
\usepackage{adjustbox}
\usepackage{multirow}

% tikz settings
\usetikzlibrary{shapes, arrows, positioning}

\raggedbottom                           % try to avoid widows and orphans
\sloppy
\clubpenalty1000%
\widowpenalty1000%

\renewcommand{\baselinestretch}{1.1}    % adjust line spacing to make
                                        % more readable

\definecolor{keywords}{RGB}{220,0,90}
\definecolor{strings}{RGB}{0,140,0}
\definecolor{comments}{RGB}{0,127,0}
\definecolor{identifiers}{RGB}{20,20,75}

\lstset{basicstyle=\ttfamily\small,
    basewidth={.5em, .3em},
    keywordstyle=\color{keywords},
    commentstyle=\color{comments},
    stringstyle=\color{strings},
    showstringspaces=false,
    % identifierstyle=\color{identifiers},
    escapechar=$ %$
    }

\newcommand{\cbox}[2]{\adjustbox{bgcolor=#1}{#2}}

\begin{document}

\bibliographystyle{plain}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title


\pagestyle{empty}

\rightline{\LARGE \textbf{Tianlin Zhang}}

\vspace*{60mm}
\begin{center}
\Huge
\textbf{An Observable OCaml} \\[5mm]
Computer Science Tripos -- Part II \\[5mm]
Jesus College \\[5mm]
\today  % today's date
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Proforma, table of contents and list of figures

\pagestyle{plain}

\chapter*{Proforma}

{\large
\begin{tabular}{ll}
Name:               & \bf Tianlin Zhang \\
College:            & \bf Jesus College\\
Project Title:      & \bf An Observable OCaml\\
Examination:        & \bf Computer Science Tripos -- Part II\\
Year:               & \bf June 2018\\
Word Count:         & \bf TODO \\
Project Originator: & Stephen Kell \\
Supervisor:         & Stephen Kell \\ 
\end{tabular}
}

\section*{Original Aims of the Project}

To write a backend for the OCaml compiler that allows compilation from OCaml 
into C in such a way that it preserves so-called ``observability'', that is the 
ability to debug the generated C code, using GDB for example, in a similar 
fashion to debugging the original OCaml code. A library of test programs should 
be written to demonstrate the capabilities of the compiler, along with an 
evaluation into the performance and observability of the compiled code.

\section*{Work Completed}

I have written and completed a new backend for the OCaml compiler which can
compile a suitable target subset of OCaml, including a majority of the most
commonly used features. A C runtime library has also been written to support the
execution of the resulting C output, as well as a library of test programs which
are used in testing and evaluation of the compiler. An evaluation has also been
performed investigating the execution times of the compiler with respect to the
OCaml native compiler, and the observability of the compiled code with the OCaml
bytecode compiler.

\section*{Special Difficulties}

None.
 
\newpage
\section*{Declaration}

I, Tianlin Zhang of Jesus College, being a candidate for Part II of the Computer
Science Tripos, hereby declare
that this dissertation and the work described in it are my own work,
unaided except as may be specified below, and that the dissertation
does not contain material that has already been used to any substantial
extent for a comparable purpose.

\bigskip
\leftline{Signed: Tianlin Zhang}

\medskip
\leftline{Date: \today}

\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% now for the chapters

\pagestyle{headings}

\chapter{Introduction}

My project concerns the creation of a new compiler for OCaml, a popular
statically typed functional language in the ML family, into the C language in
such a way as to be able to take advantage of debugging tools provided by the C
toolchain. This property, henceforth referred to as ``observability'', refers to
the ability to view the execution of the program through a debugger as if it was
debugging a C program and to recover the program's execution state.

I have successfully implemented a compiler for a core subset of the OCaml
language in to C, which when compiled with a standard C compiler such as
\texttt{gcc} or \texttt{clang} produces an executable that behaves in an
identical way up to minor differences with the output of the native OCaml
compiler. Additionally, when compiled with the \texttt{-g} flag, the resulting
executable can be debugged under \texttt{gdb} in such a way that preserves the
execution order of the original OCaml source, and allows setting breakpoints and
observing values in the OCaml code in the same way as if it were debugging the
original OCaml code.

\section{Motivation}

There are several motivations for this project, including:

\subsubsection{Observability}

The OCaml debugger was introduced fairly recently, and only works on compiled 
bytecode; in addition, since OCaml strips away type information on actual 
values at runtime, the debugger is unable to inspect the values of certain 
variables within polymorphic functions.

We can consider the following example OCaml code:

\begin{lstlisting}[language=Caml]
let id x = x
let a = id 2
\end{lstlisting}

Running this through the OCaml debugger, we see that it is unable to determine
the value of the variable \texttt{x} within the \texttt{id} function.

\begin{lstlisting}
(ocd) break @ Id 1
Breakpoint 1 at 10156: file id.ml, line 1, characters 12-13
(ocd) run
Time: 12 - pc: 10156 - module Id
Breakpoint: 1
1 let id x = <|b|>x
(ocd) print x
x: 'a = <poly>
\end{lstlisting}

Compiling to C could take advantage of a different data representation, and GDB
extensions to customise debugger behaviour, allowing GDB to `see-through'
polymorphic values such as this..

\subsubsection{Plausibility} There are many language features in OCaml which do
not have similar analogues in C. Examples of these include algebraic data
structures, partial application, lexical closures, and polymorphic datatypes and
functions. I was interested in whether despite these differences, I could create
appropriate transformations to simulate these in C but preserve observability at
the same time, giving an OCaml view into what the code is doing.

\subsubsection{Performance}

By compilation to C, I can take advantage of the fact that the most popular C 
compilers have undergone decades of optimisation to produce very performant 
code. We can exploit this to obtain very fast executables without needing to 
perform much optimisation on the OCaml code. There will however be performance 
trade-offs in terms of emulating OCaml function calls in C compared to normal 
function calls, as OCaml functions can take advantage of features such as
lexical closure and partial application, as well as being first-class allowing
them to be passed as values to higher-order functions.

\section{Previous Work}

There exist prior work for compiling ML-like languages into C
\cite{noassemblyrequired} but the approach used is to transform the program into
continuation-passing style, which is not suitable for the compiler as it would
interfere with the program execution and make it untenable to map OCaml source
code into regions of the compiled code for debugging purposes, but shows that
compilation into C from similar functional languages is feasible.

In addition, this project was also attempted in previous years by a previous
student \cite{previousproject} under the same supervisor with a similar starting
point, but my approach to the design of the compiler was not influenced and it
is of my opinion that a sufficiently different approach was used for this
project. A different representation of the output C code was used leading to a
different compiler structure from the outset of the project, as well as
completely different approaches being taken for more complex features in OCaml,
such as data representation and closure conversion.

\chapter{Preparation}

Before starting the project I have had significant experience with functional
languages through the Standard ML course undertaken and also personal experience
with programming in Haskell, but however I had never used OCaml at length, nor
worked with the OCaml compiler codebase. While OCaml was very simple to learn
from my previous experiences with functional languages, the OCaml compiler
codebase much to my chagrin was large, complex, and very sparsely commented.

In this respect, a large portion of time during the starting weeks of the 
project was focused on reading through barely-commented source code in order to
understand the different data types used by the OCaml compiler, as well as
research into various options for different libraries to use.

\section{Starting point}

The starting point of this project is the existing OCaml
compiler\footnote{\url{https://github.com/ocaml/ocaml}}, as it would be too
onerous to duplicate the effort of parsing and performing type inference on
OCaml source code. Instead, my compiler takes the \texttt{Lambda} intermediate
representation from the OCaml compiler and compiles this into C. Since the OCaml
compiler backends Asmgen and Bytegen, which produce the native binaries/bytecode
executables, also only take the \texttt{Lambda} IR, this approach is akin to
introducing a new compiler backend or different target for compilation.

\begin{figure}
    \centering
    \input{./figs/compiler_structure.tex}
    \caption{A representation of the various stages in the OCaml compiler. 
    Adapted from \cite[Chapter~22]{realworldocaml}.}
    \label{fig:compilerstages}
\end{figure}

The rest of this section will address why this was chosen as the starting 
point, and the process during the preparation phase in which the appropriate 
starting point was determined.

\subsection{Intermediate representations}

The OCaml compiler processes code in the pipeline shown in figure
\ref{fig:compilerstages}, with the pipeline branching towards the end into two 
separate stages representing the targets that the OCaml compiler can compile 
to. Between each stage, a different intermediate representation of the code is 
produced.

One of the tasks that had to be carried out during the preparation phase was 
to determine which intermediate representation would be most suitable for 
compilation into C. The requirements required for such an intermediate 
representation would be:

\begin{itemize}

\item It must be easy to recover type information from the representation. This
    is because the resulting C code must be statically typed also, so we need to
    be able to infer the types of variables and functions in order for them to
    be implemented in C.

\item The representation must be fairly normalised, with as few as possible
    language constructs to simplify the translation into C. Many language
    features in OCaml are merely syntactically sugared versions of more
    primitive ones (for example, pattern matching is really a combination of
    branching based on the value of a variable plus some variable bindings for
    unpacking) which must have been desugared anyway during the compilation
    process, so it would be more useful if we could utilise an intermediate
    representation for which this has already happened.

\item The representation must also allow some amount of reconstruction back to
    the source level, as this is important so we can map the output code to the
    correct sections of the source code, which is important for observability
    and debugging as we would like debuggers to display the correct segments of
    code being debugged. This does present an antagonism, where we would like
    the IR to be both normalised, but not enough that we cannot recover any
    source-level information from it.

\end{itemize}

\subsubsection{\texttt{Parsetree}}

\texttt{Parsetree} is a parsed AST representation of the source code, which 
essentially directly represents the original OCaml source code. No processing 
has occurred on any language constructs, and type inference has not even 
occurred on the IR. This obviously makes this intermediate representation 
unsuitable as the choice of IR, since it falls down on both ability to recover 
type information and normalisation.

\subsubsection{\texttt{Typedtree}}

\texttt{Typedtree} is a type-annotated AST which is almost exactly identical to 
the \texttt{Parsetree} IR, except that expressions have been annotated with a 
type. This makes this IR highly desirable as the starting point for compilation 
into C, and was initially where the investigation for a usable intermediate 
representation started.

However, since \texttt{Typedtree} still almost directly represents the original
source code, it suffers from the same normalisation problem as
\texttt{Parsetree} does. For example, the number of different sub-expression
cases that \texttt{Parsetree} represents separately is 31 --- modules, classes
and objects are still represented as syntactical elements; records, variants,
and field accesses have not been normalised into one representation; and pattern
matches have not been simplified but instead stored as association lists of raw
patterns to expressions.

This makes the \texttt{Typedtree} IR very cumbersome to work with, and 
ultimately it was considered unsuitable for the starting point of the project.

\subsection{The \texttt{Lambda} IR}

The \texttt{Lambda} IR is so named because it resembles an untyped lambda 
calculus, and is what in fact the two existing backends of the compiler 
generate code from. It has a number of advantages over \texttt{Parsetree} and 
\texttt{Typedtree}, including:

\begin{itemize}

\item Variants and records have been normalised into one representation, which
    is referred to as a block, which are similar to tagged unions. In addition,
    variants without parameters are compiled into bare integers.

\item Desugaring of pattern match statements. Because variants have been
    compiled into integers or tagged unions, the translation pass is able to
    optimise pattern matching into switch statements. In very simple cases,
    pattern matches are in fact compiled into an if-else statement instead.

\item Removal of modules and functors. These values have instead been compiled
    into equivalent representations using blocks and functions.

\end{itemize}

In comparison to \texttt{Typedtree}'s 31 different cases for sub-expressions, 
the \texttt{Lambda} representation has 20 different cases, which are relatively 
much simpler than those in \texttt{Typedtree}. This makes the \texttt{Lambda} 
IR far more desirable as a starting point.

However, there are some major disadvantages of the \texttt{Lambda} IR:

\begin{itemize}

\item The translation pass into \texttt{Lambda} does not preserve much of the
    type information from \texttt{Typedtree}. This is a huge problem which is
    solved somewhat with the existence of \texttt{Lambda} events, which will be
    discussed in \S\ref{lambda-types}.

\item Normalisation in the \texttt{Lambda} IR discard a lot of source-level
    information such as which source-level expressions \texttt{Lambda}
    expressions map to, as well as having very little information about the
    location in the source code of the current code. This is somewhat remedied
    with \texttt{Lambda} events, which is discussed in \S\ref{line-directive}.

\item The \texttt{Lambda} IR has not yet had closure conversion applied to it.
    Functions are still represented in a similar fashion to how they were in the
    original source code, meaning the cases of lexical closures, partial
    application, etc. are not handled.

\end{itemize}

It was determined that while the \texttt{Lambda} IR does not fully satisfy the
typing and source reconstruction requirements, enough type and source
information was recoverable that it was deemed acceptable as a starting point.
Thus, my project starts compilation by obtaining the \texttt{Lambda}
representation by passing the source code through part of the compilation
pipeline, and then translates the resulting IR into C from that point onwards.

\section{Extensibility of GDB}

Part of the project requirements dictate that the resulting code be 
``observable'', and it was quickly identified that if GDB is to be used as the 
primary debugger it may be necessary to extend GDB in order to handle the 
compiled OCaml code correctly and display recursive OCaml values. Thus, a brief 
investigation into GDB was carried out in the preparation phase to investigate 
its extensibility.

One of the experiments which was carried out was to see if GDB could display
code from other files, and associate parts of compiled C code with instead parts
of code from another file. This is a necessary part of the compilation process,
as the resulting debuggable executable must display code and symbols from the
original OCaml file from which it was compiled from via my compiler, not the C
file that my compiler produces. With some investigation it was found that this
was possible with the \texttt{\#}\texttt{line} directive, which is explored in
\S\ref{line-directive}.

Another feature which is required for observability is the ability to display 
OCaml values at least recursively, if not formatted in the same way as the 
OCaml compiler does. This is because many OCaml values are recursive (for 
example, the list type is a recursive type which refers back to itself as one 
of its parameters) so it must be possible to extend GDB with some way to 
recursively print values whenever it finds a pointer. It was found that GDB 
does support extensions to itself via custom macros, and also supports custom 
pretty-printers (via, for example, Python) for different types. Either of these 
features would allow GDB to display OCaml values correctly.

\section{Target subsets}

During the write-up of the project proposal, three expanding subsets of OCaml 
were identified in order to structure the creation of the compiler around. 
These subsets represent a grouping of similar constructs and features together 
such that each subset focuses on a similar theme in the new features it 
introduces.

Identification of these subsets firstly has the benefit of providing a clear 
structure to the project, and greatly influenced the order in which features 
were implemented. Optimistically, it was expected that at the end of proposed 
deadlines a compiler would be completed that could compile the associated 
Subset -- unfortunately, due to interdependence between a lot of the features a 
working compiler was not produced until towards the end of implementing 
features for Subset 2.

These subsets also serve to identify what the minimum viable product of the 
project is, as it was determined on project conception compilation of the 
entire OCaml language would be far too ambitious. As such, Subset 3 represents 
the subset of the language that the final product should at minimum be able to 
compile correctly.

Despite the fact that the subsets ultimately did not produce distinct and 
recognisable milestones for compilers that could operate on the appropriate 
subsets of the language, it is still worth describing the subsets for the 
effect they had on the planning for the rest of the project.

\subsection{Subset 1}

Subset 1 is a very simple language with only a limited number of types and 
language constructs. This subset contains only basic boolean, integer, floating 
point, and \texttt{unit} types, only basic string support (for input/output), 
top level function declarations with \texttt{let} and \texttt{let rec}, and 
basic language constructs such as \texttt{if}, \texttt{for}, and \texttt{while}.

\subsection{Subset 2}

Subset 2 expands on Subset 1 by introducing custom types and polymorphism. This 
includes tuples, lists, variant types via algebraic data types, record types, 
match expressions and function parametric polymorphism. This subset is aimed 
towards designing and implementing an appropriate representation of OCaml 
values in C, as well as a way of representing polymorphic values both as values 
in user-defined types and as parameters to functions.

\subsection{Subset 3}

Subset 3 expands further on Subset 2 by adding treatment of functions as first
class values, plus closure conversion features, which would entail compilation
of lexical closures, partial application, anonymous functions, etc. The focus of
this subset is intended towards the design and implementation of closures in C,
and correctly compiling the more difficult features of OCaml functions into C.

\section{The \texttt{liballocs} library}

\texttt{liballocs}\cite{liballocs} is a library that is able to track all
allocations in memory and their associated types with no extra required effort.
It exposes an interface that, when given an arbitrary pointer, is able to return
information about the type of the value in the allocated memory. This was
identified to be extremely useful for implementing observability features, as it
could be used within polymorphic functions to determine the type of certain
values whilst debugging at runtime, which would be an advantage over the OCaml
bytecode debugger, which due to the untagged nature of OCaml values cannot
determine the type of polymorphic values at runtime.

Unfortunately, it was deemed that explicit tagging of types was easier to
implement than inclusion of the \texttt{liballocs} library, but future
extensions to the compiler may incorporate it to provide more detailed typing
information.

\section{The Boehm GC}

Since the target subset aims to include a significant portion of OCaml including
parts which allow for data structures and closures to be created. It is
necessary that the runtime would require some sort of garbage collection. For
reference, the OCaml native compiler includes as part of its runtime a
specialised garbage collector written specifically for OCaml programs.

Writing a new garbage collector would be very complex and heavily outside the
scope of the project, so we would like to make use of a pre-existing solution
for garbage collection in C. Fortunately, many garbage collectors exist, and the
Boehm GC\footnote{\url{http://www.hboehm.info/gc/}} was selected and used.

The Boehm GC is a garbage collector for C and C++, which exposes a function
\texttt{GC\char`_MALLOC} which can works as a replacement for \texttt{malloc}.
Whenever \texttt{GC\char`_MALLOC} is called, it runs the garbage collector by
scanning the stack for values that could potentially look like pointers and so
performing garbage collection. This means that in simple cases, it can be used
as a drop-in solution for GC without extra configuration.

\section{Setting up the environment}

The source code of the compiler was managed using \texttt{git}, the repository
of which was backed up by publishing to
GitHub\footnote{\url{https://github.com/t-veor/observable-ocaml}}. Development
initially took place on the master branch, but once the compiler approached
feature completeness new features in the compiler would be developed in a forked
branch, worked on until they pass the regression tests, and then merged into the
master branch.

In addition, a copy of the source code was continuously backed up using Dropbox,
which was synced between two local copies of the code, on two separate machines.
In this way, the code had four points of redundancy in the case of any computer
failures.

\section{Licensing of external code}

The principal body of code being used is the OCaml core
system\footnote{\url{https://github.com/ocaml/ocaml/blob/4.05/LICENSE}}, which
is released under LGPL v2.1. LGPL is a more permissive version of the GPL
license, intended for use for libraries rather than full pieces of software. The
LGPL license puts restrictions on what it calls ``derivative works of the
Library'', which are either modifications of the library or other software that
includes the library or statically link to it, requiring that these derivative
works are open source and also released with either the LGPL or the GPL library.

However, software that is designed to work with the library by linking against
it but does not actually contain any portion of the library fall outside the
scope of the license, which is the case with my compiler. As I am only releasing
the source code of the compiler, which do not contain parts of the OCaml core
system but link against it, the LGPL terms do not apply to the source code. They
would however apply if I decided to release a compiled executable which has
statically linked in the OCaml core system, but in fact a special exemption in
the OCaml's core system also covers this, allowing works which statically or
dynamically link with a publicly distributed version of the OCaml core system
to be exempt from the clauses of LGPL.

The other main library used is the Boehm
GC\footnote{\url{http://www.hboehm.info/gc/license.txt}}, which uses a custom
permissive free software license, allowing for distribution and modification as
long as a copy of the license is distributed with the library. This means in
fact that my code is not within the scope of the license, since I do not
distribute any part of the Boehm GC, but merely link against it in the
compilation process. I have included the license within my repository
nonetheless.

\chapter{Implementation}

In the implementation, several modules were written in OCaml 
for implementing different parts of the compiler. The most significant modules 
were:

\begin{itemize}
\item \texttt{Typecollect}, for obtaining types from the \texttt{Lambda} IR;
\item \texttt{Ccode}, for representation of C compilation target;
\item \texttt{Ccompile}, for the actual compilation process from the 
\texttt{Lambda} IR to C.
\end{itemize}

\begin{figure}
    \centering
    \input{./figs/compiler_pipeline.tex}
    \caption{A representation of the stages in producing an executable output
    from my compiler, starting from the \texttt{Lambda} IR.}
    \label{fig:compilerpipeline}
\end{figure}

\section{Obtaining types from the \texttt{Lambda} IR} \label{lambda-types}

The \texttt{Lambda} IR does not have any type information associated with it, as
within the OCaml compiler, \texttt{Lambda} was intended as the last
representation before compilation into actual machine code, so all type
information was erased from the underlying data.

While not having types isn't such a big problem for the compilation into C, one
of the goals of the project was to have the resulting code be ``observable'',
which means where possible variables should be of a meaningful type in order to
be displayed correctly in GDB.

\subsection{\texttt{Lambda} Events} \label{levents}

The OCaml compiler inserts \texttt{Lambda} events into the \texttt{Lambda} IR
when the debug flag is set. A \texttt{Lambda} event is simply a wrapper around
another \texttt{Lambda} expression that carries some extra information, which
includes the potential type of an expression and the current location in the
source code.

Within the OCaml compiler, the purpose of a \texttt{Lambda} event is to mark
where an interesting expression may be, so that the debugger may stop execution
and inspect the state of the program just before the evaluation of the
expression, or just after. This gives \texttt{Lambda} events two main useful
properties, which are:

\begin{itemize}

\item \texttt{Lambda} events provide information about the current source code
    location of the expressions being currently compiled, which will be useful
    in for specifying source location (see \S\ref{line-directive});

\item \texttt{Lambda} events provide type information about types of certain
    expressions.

\end{itemize}

Unfortunately, the compiler does not insert events that give types for every
expression, nor is there a one-to-one correspondence between \texttt{Lambda}
expressions and source-code expressions, since the \texttt{Lambda} IR may
simplify certain expressions or insert new ones. However, every source-code
variable was associated with at least one \texttt{Lambda} event describing its
type. Therefore, determining types of variables used the \texttt{Lambda} events,
and types of compound expressions were determined with very basic type-
inference.

\subsection{The \texttt{Typecollect} module}

The \texttt{Typecollect} module therefore has a function \texttt{scrape} which
does the following:

\begin{enumerate}

    \item Initialise a hash table of variable identifiers to types
    (this is safe as the \texttt{Lambda} IR already assigns a different 
    identifier to every variable)

    \item Walk recursively down the \texttt{Lambda} tree:

    {\setlength{\itemindent}{25pt} \item Upon encountering a \texttt{Lambda} 
    event surrounding a variable:}

    {\setlength{\itemindent}{50pt} \item Set the variable and its type in the 
    hash table}

    \item Return the now-filled hash table.

\end{enumerate}

This preliminary pass over the \texttt{Lambda} IR passes the infered types to
the \texttt{Ccompile} module.

\section{Representation of C}

Before compilation can start, an appropriate representation of C must be chosen 
as the compilation target for the compiler.

\subsection{Expressions to statements} \label{expr-stmt}

OCaml is what is known as an expression-oriented programming language, where
every syntactical construct is actually an expression of some kind. This is in
contrast to C, which is statement-oriented. Contrast for example the following
(slightly contrived) piece of code in OCaml and C:

\begin{lstlisting}[language=Caml]
let sq_max_plus_one x y =
    (let m = if x > y then x else y in m * m) + 1
\end{lstlisting}

\begin{lstlisting}[language=C]
int sq_max_plus_one(int x, int y) {
    int m;
    if (x > y) {
        m = x;
    } else {
        m = y;
    }
    return m * m + 1;
}
\end{lstlisting}

To solve this problem, my compiler assigns every sub-expression in the program
to a separate variable. This means that if an expression consists of just a
variable, use the variable name directly; otherwise, create and assign the
result of each sub-expression to a new temporary variable.

By setting up a variable for each sub-expression, this creates an equivalence
between variables and sub-expressions. The compilation of any expression
therefore generates some sequence of statements, by the end of which the value
of the expression is assigned to a variable. The compilation function therefore
adds the statements to the current context, and returns the variable. 

\subsection{The \texttt{Ccode} module}

The \texttt{Ccode} module is a module of the compiler that simply stores the
type declarations for the internal representation of C. More details is given in
the appendix at \S\ref{ccode}.

\subsection{The \texttt{Cprint} module}

The \texttt{Cprint} module is another module that's fairly straightforward --
it contains functions for printing types from \texttt{Ccode} to an output
stream, most likely a file. Its functions simply recursively traverse down the
\texttt{Ccode} representation and prints out the corresponding C as it goes
along.

\section{Compiler basics}

Structures from Subset 1 were implemented first, which included basic
structures, some of which are included below. In the interest of brevity other
more trivial structures are described in the appendix at
\S\ref{basic-constructs}.

\subsection{\texttt{let} bindings}

When compiling let bindings, special attention needs to be paid to the variable
scoping (see \S\ref{variable-scoping}). In OCaml, a \texttt{let} binding has the
structure:

\begin{center}
    \texttt{let \emph{x} = \emph{expr} in \emph{body}}
\end{center}

Note that \texttt{\emph{x}} is not a free variable of \texttt{\emph{expr}} 
but is one in \texttt{\emph{body}}, and also that the value of the overall 
expression is the evaluated value of \texttt{\emph{body}}. Thus, a block is 
required to emulate the scoping correctly.

We therefore define the compilation of \texttt{let} bindings like thus, using
the notation defined in \S\ref{meta-notation}:

\begin{lstlisting}
comp<let $\emph{x}$ = $\emph{expr}$ in $\emph{body}$> :=

declare result;

comp<$\emph{expr}$>;
declare temp = var<$\emph{temp}$>;
{
    declare x;
    x = temp;
    
    comp<$\emph{body}$>;
    result = var<$\emph{body}$>;
}
\end{lstlisting}

\texttt{\emph{expr}} must be evaluated outside of the inner scope, where
\texttt{\emph{x}} is visible, and \texttt{\emph{body}} must be evaluated inside
the inner scope. We declare and assign the value of \texttt{\emph{x}} only
inside the inner scope. In addition, the actual value of \texttt{\emph{expr}}
must then be available outside the inner scope, so we propagate it outwards by
declaring a variable \texttt{result} in the outer scope and performing its
actual assignment in the inner scope.

OCaml also allows \texttt{let} bindings to be a shorthand for function
declaration; function compilation will be discussed in \S\ref{functions}.

\subsection{Recursive bindings with \texttt{let rec}}

Normally in a let binding, the variable being bound is not in scope for the
expression being bound. This however makes it difficult to define recursive
functions, so OCaml supplies the \texttt{let rec} binding which is useful for
creating recursive functions, or sets of mutually recursive functions. For
example, consider the following functions:

\begin{lstlisting}[language=Caml]
let rec add x y =
    if x = 0 then y else add (x - 1) (y + 1)

let rec even n =
    if n = 0 then true else odd (n - 1)
and odd n =
    if n = 0 then false else even (n - 1)
\end{lstlisting}

However OCaml allows \texttt{let rec} bindings to be used for creating a
restricted class of non-functional recursive values. The typical example given
is:

\begin{center}
    \texttt{let rec x = 1::y and y = 1::x in \emph{expr}}
\end{center}

This binds \texttt{x} to the infinite list \texttt{1::2::1::2::...}, which is
accomplished by making the list cyclical. Unsurprisingly, this is very rarely
used feature within OCaml, but in the interest of fully supporting all features
within our OCaml subset we would also like to compile expressions like this
correctly.

Informally, the class of values that are allowed to be used as the right-hand
side of a \texttt{let rec} binding are those where the recursively bound names
occur only within a function, or a data constructor. This means that to preserve
the semantics in C, the compiler therefore compiles \texttt{let rec} in two
phases:

The compiler thus splits compilation of \texttt{let rec} into two phases:

\begin{itemize} 
    
\item Variables are declared. If the associated expression has no free variables
    that are bound as part of the same \texttt{let rec}, evaluation can happen
    immediately; otherwise, its size is determined and then space for them is
    allocated with \texttt{malloc}, issuing them addresses in the process.        

\item Once all addresses are known, evaluation proceeds using the obtained
    addresses in place of variables which reference a value bound in the
    \texttt{let rec}.

\end{itemize}

\section{OCaml value representation} \label{value-repr}

This section largely details work undertaken to implement Subset 2, which deals 
with data representation and the language structures surrounding them.

\subsection{Representation requirements}

Before discussing the strategy for representing OCaml values, it is useful to
discuss the problems that the value representation needs to solve.

\subsubsection{Polymorphic types}

Polymorphic code does not know the precise type of values it is manipulating, so
cannot deal with variable size data as they may not copy polymorphic values
correctly.

\subsubsection{OCaml blocks}

More complex types such as tuples and records are represented by a construct
known as an OCaml block, which is a variable length array of values with a
header containing its length and an integer tag value.

The \texttt{Lambda} IR in fact normalises all data structures into blocks, 
including references (they're a mutable singleton block), arrays, modules etc. 
which is rather convenient as we can implement all of these data types for free 
by implementing blocks.

\subsubsection{Algebraic Data Types}

A major feature in OCaml is the ADT, which combines elements of both enums and
record types. As an example, consider the following type declaration:

\begin{lstlisting}[language=Caml]
type color =
  | Red
  | Green
  | Blue
  | Gray of int
  | RGB of int * int * int
\end{lstlisting}

The data constructors (\texttt{Red}, \texttt{Green}, \texttt{Blue},
\texttt{Gray}, and \texttt{RGB}) within an ADT declaration are referred to as
variants, and the type is a union of all of these types together. In the
\texttt{Lambda} IR, data constructors that do not have any parameters are
represented as integers starting from 0 (so \texttt{Red} is 0, \texttt{Green} is
1, and \texttt{Blue} is 2), and data constructors that do are represented using
OCaml blocks, with tag values starting from 0 (so \texttt{Gray} is an OCaml
block of size 1 with tag 0, and \texttt{RGB} is an OCaml block of size 3 with
tag 1). This is the significance of the tag values -- they differentiate
between different variants in ADTs.

\begin{figure}
    \centering
    \input{./figs/block_header.tex}
    \caption{Example OCaml block containing two values with tag 0.}
    \label{fig:block-header}
\end{figure}

\subsection{Representation strategy}

As a consequence of the fact that we want the resulting C code to be observable,
whenever there is an exact primitive type the C code should attempt to use the
equivalent type in C as much as possible.

Representation for non-primitive types however is more complex. Integer types
and OCaml blocks must be unified in representation, because variants that don't
have any parameters and variants that do can be of the same type.

\subsubsection{Tagged pointers}

OCaml blocks must be allocated on the heap since they are of variable size, so
have to be referenced using a pointer. This means that we need a type than can
either be a pointer or an integer, which is what tagged pointers provide.

Tagged pointers are just a union type between pointers and integers. On most
architectures, pointers are word-aligned, meaning that the lower bits of a
pointer are always 0. The tagged pointer approach employed in this compiler is
to use the least significant bit of an 8-byte word as the tag bit to
differentiate between pointers and integers, and the remaining 63 bits to store
the integer or pointer.

There is a choice as to which way round the tag bit should be -- should 0 
represent integers or pointers? I chose to use 0 for pointers, and 1 for 
integers, which means that the ``boxed'' version of a pointer is identical to 
the pointer in memory. This has the effect that dereferencing pointers is cheap
and we can use a conservative GC with no modification -- see \S\ref{gc}.

\subsubsection{Polymorphic values}

We can use the tagged pointer representation to represent polymorphic values as
well, by boxing all non-integer values into a block. To disambiguate these
blocks from other normal blocks so that at runtime, the debugger is able to see
what type they really are, we assign a special tag to them which for example
marks the block as containing only \texttt{float}s or \texttt{string}s.

\begin{figure}
    \centering
    \input{./figs/block_example.tex}
    \caption{Example box-and-pointer diagram for the list \texttt{[1.0; 2.0;
        3.0]}. Floating point numbers must be boxed to be stored in a block, so
        a special block is created for each one with the special tag 253.}
    \label{fig:block-example}
\end{figure}

\subsection{Representation in C} \label{c-repr}

By taking advantage of flexible array members, it is easy to implement an OCaml 
block in C.

\begin{lstlisting}[language=C]
typedef struct _block {
    uintptr_t size : 56;
    uintptr_t tag : 8;
    any_type data[];
} block;
\end{lstlisting}

Recall that a block needs to store its size, an integer tag, and any number of
other OCaml values. Since OCaml tags only range between 0-255\footnote{In fact,
    the native OCaml runtime restricts the number of possible variants to 246,
    using the tags 0-245 for variants. It uses the last 10 possible tags for
special tags.}, and 45 bits are sufficient for storing the size of a block in
words, we can reduce the amount of space used for the header using C bit-fields.
This means the header only needs to be one word long.

We can now implement actual OCaml values as a union type:

\begin{lstlisting}[language=C]
typedef union _value_type {
    intptr_t i;
    block* block;
} value_type;

#define BOX_INT(v) ((value_type){.i = (intptr_t)(v) << 1 | 1})
#define UNBOX_INT(v) ((v).i >> 1)

#define BOX_BLOCK ((value_type){.block = (v)})
#define UNBOX_BLOCK ((v).block)

#define IS_INT(v) ((v).i & 1)
\end{lstlisting}

\verb|BOX_INT| and \verb|UNBOX_INT| demonstrate how to box integers into a 
\verb|value_type|, and likewise for block pointers. We also have a special 
macro \verb|IS_INT|, which checks if a \verb|value_type| is holding an integer 
or a pointer -- it simply checks the last bit, returning 1 if the last bit is 
also a 1.

\subsubsection{Type-punning with \texttt{any\char`_type}}

While \texttt{block}s normally hold an array of other \verb|value_type|s, we
would like to have special blocks that represent the result of boxing certain
other primitive types, such as \texttt{float}s and \texttt{strings}. To do this,
we declare a union type \verb|any_type|\footnote{For clarity, we ignore the
problems associated with recursive type definitions in C, assuming the correct
forward declarations.}:

\begin{lstlisting}[language=C]
typedef union {
    double fl;
    char* str;
    value_type value;
} any_type;
\end{lstlisting}

\texttt{block} therefore declares a \verb|any_type| array to support both
storing \verb|value_type|s as well as special blocks that store \verb|double|s
and \verb|char*|s.

\subsection{Conversion between C types} \label{casting}

Despite the \texttt{Lambda} IR having already gone through type inferencing,
there are still a few cases in which ``casting'' is necessary. This is because,
for example, the C types for polymorphic types and monomorphic types in OCaml
are different, so a C cast is necessary when passing a value of a known type to
a polymorphic function.

In general, there are several cases where we need to perform a conversion
operation in C. These cases are: 

\begin{itemize}

\item A conversion from an integer to an OCaml value is required, because the
    \texttt{Lambda} IR uses integers for representing certain non-integer OCaml
    values.

\item A conversion from any other type to an OCaml value, because a variable is
    being passed into a polymorphic function, or being placed into a block.

\item An actual conversion between types, such as from integers to floating
    point numbers.

\end{itemize}

The cases all involve a mismatch between the C types of two expressions, so are
handled using a function that does the following:

\begin{enumerate}

\item If the source and target types are the same, do nothing.

\item If either type is \verb|any_type|, pack or unpack the value as
    appropriate. 

\item If either type is \verb|value_type|, box or unbox the value as
    appropriate.

\item Otherwise, perform a C cast between source type and target type.

\end{enumerate}

\subsection{Pattern matching}

OCaml employs pattern matching in many constructs of the language, particularly
in its \texttt{match} expressions. Fortunately, the \texttt{Lambda} IR usually
compiles these down to an equivalent set of \texttt{if} expressions and
\texttt{let} bindings. In the case of variants however, pattern matching
typically compiles down into a \texttt{Lswitch} expression.

\subsubsection{\texttt{Lswitch} expressions}

\texttt{Lswitch} expressions correspond to match statements on a variant 
expression. For an example, consider the type and match expression:

\begin{lstlisting}[language=Caml]
type color =
  | Red
  | Green
  | Blue
  | Gray of int
  | RGB of int * int * int

match c with
  | Red -> 0
  | Green -> 1
  | Blue -> 2
  | Gray x -> 3
  | RGB (r, g, b) -> 4
\end{lstlisting}

This match statement is compiled into the following \texttt{Lambda} expression:

\begin{lstlisting}
(switch* c/xxxx
  case int 0: 0
  case int 1: 1
  case int 2: 2
  case tag 0: 3
  case tag 1: 4)
\end{lstlisting}

There's one important difference between this and a C switch statement: each of
the cases predicate on both whether the value is an integer or a block in
addition to its value or tag.

One \texttt{Lswitch} statement therefore compiles into two switch statements in
C, one for the integers and one for the tags, which are the two branches of an
if statement that checks if the value being switched on is an integer or a value
using the tagged pointer check.

\section{Function compilation and closure conversion} \label{functions}

Functions and closures are the final major feature required to compile the
target subset of OCaml into C. The following sections will discuss the
motivations for a closure representation and the implementation of such a
representation, which is the majority of work undertaken in the implementation
of Subset 3.

\subsection{Local functions}

All functions in C are required to be defined at top-level, which means that 
nested function declarations are not possible. This is in contrast to OCaml, 
where function definitions are simply expressions like any other, and thus can 
be defined locally and passed as values. In order to emulate this behaviour in 
C, whenever we come across a function definition we lift the function 
definition to the toplevel scope, compile the function there, and then return 
its function pointer when we come back.\footnote{This clearly does not deal 
with lexical closures, so we actually return a pointer to a closure object 
instead of a function pointer, but the idea is the same.}

We can write the compilation of a local function like thus, using the notation
from \S\ref{meta-notation}:

\begin{lstlisting}
comp<fun $\emph{args...}$ -> $\emph{body}$> :=

/* in top-level */
$\emph{return\char`_type}$ local_function($\emph{args...}$) {
    comp<$\emph{body}$>;
    return var<$\emph{body}$>;
}

/* in current context */
declare result = &local_function;
\end{lstlisting}

\subsection{Function Types in C} \label{function-typing}

In OCaml, one way of viewing functions is always as functions of one argument,
which can return other functions. As an example, the function type \texttt{int
-> float -> int} represents a function that takes an integer and returns a
\texttt{float -> int}, which is a function that takes a floating point number
and returns an integer.

While this is a correct high-level view of functions, this is not suitable for a
low-level implementation at all, since it is much more efficient for functions
to actually accept multiple arguments instead of taking one argument at a time.

In C by contrast, a function declaration consists of a return type, and a list 
of input arguments. We therefore need a consistent conversion between OCaml 
function types and C function types, so we pick the most obvious one -- all the 
types in the OCaml function type are the arguments to the C function, and the 
final type is the return type of the C function.

For example, a function of type \texttt{int -> float -> str} is compiled to
\texttt{char* (*)(int, double)} in C.

\subsection{Closure representation}

Closures are, implementation-wise, a structure that stores both a function 
pointer and an environment, containing values required for the execution of the 
function.

Our closure representation essentially requires storing a function pointer and 
some list of values, so taking advantage of flexible array members again we 
arrive at the following definition:

\begin{lstlisting}[language=C]
typedef struct _closure_type {
    void* (*f)();
    struct _closure_type* next;
    any_type$\footnotemark$ args[];
}
\end{lstlisting}

\footnotetext{Note that we are reusing \texttt{any\char`_type}, which means we
need to extend its definition and the casting rules to accept more types, such
as integers, function pointers, and closure types.}

As you can see, this definition contains a function pointer, and a
variably-sized array of arguments, which we reused \verb|any_type| from
\S\ref{c-repr} to implement. Closures also have a \texttt{next} field which
points to another \verb|closure_type|, allowing them to act like a linked list.
The motivation of this is discussed in partial application compilation, in
\S\ref{partial-app}.

\subsubsection{Using closure objects}

In order to make the closure object useful, we modify all functions to instead
take an extra parameter, \texttt{closure\char`_type* closure\char`_obj}, which
stores the pointer to the current closure object. From there, the function is
able to access closure values by indexing \verb|closure_obj->args|.

Calling a closure can be done by invoking the function pointer with the 
required arguments, passing in the closure pointer as the last argument.

\begin{lstlisting}[language=C]
cl->f($\emph{args...}$, cl);
\end{lstlisting}

\subsubsection{Promoting ordinary functions to closures}

This necessitates some sort of promotion process where functions that do not
require environment capture are promoted to closures. This is done by creating
another function which takes all the same arguments as the original function
plus the closure object. This function just passes the arguments along to the
original function.

\begin{lstlisting}[language=C]
$\emph{return\char`_type}$ promoted_closure($\emph{args...}$, closure_type* closure_obj) {
    return f($\emph{args...}$);
}

closure_type* cl = MALLOC(sizeof(closure_type));
cl->f = (void*(*)())&promoted_closure;
cl->next = NULL;
\end{lstlisting}

\subsubsection{Unification of closures and functions}

For ease of representation, it was decided to unify functions and closures in C
as well. This means that all functions are promoted to closures, and all
function applications in OCaml are compiled into closure calls in C, simplifying
the implementation at the cost of possible performance losses.

\subsection{Partial application compilation} \label{partial-app}

Partial application is one of the major use-cases for closures, and is modelled
in my compiler using a closure object. Whenever there is a partial application,
a function is created instead that takes the remaining parameters, and a closure
object is created to store the partially-applied arguments. The newly created
function simply obtains the previously partially applied arguments from the
closure object and passes them along with its own arguments to reconstruct the
original function call.

As an example, observe the following C-style pseudocode, where a closure
\texttt{cl\char`_f} (which requires three integer arguments and returns an
integer) is partially applied with two integers, \texttt{a} and \texttt{b}, and
another closure \texttt{cl\char`_g} is returned\footnote{Cast operators have
been omitted for simplicity.}.

\begin{lstlisting}[language=C]
int g(int c, closure_type* closure_obj) {
    int arg_0 = closure_obj->data[0];
    int arg_1 = closure_obj->data[1];
    
    closure_type* cl = closure_obj->next;
    cl->f(arg_0, arg_1, c, cl);
}

closure_type* cl_g = MALLOC(sizeof(closure_type) + sizeof(any_type)*2);
cl_g->f = &g;
cl_g->next = cl_f;
cl_g->data[0] = a;
cl_g->data[1] = b;
\end{lstlisting}

\begin{figure}
    \centering
    \input{./figs/partial_app.tex}
    \caption{Example result of a partial application of a function \texttt{f(a, 
    b, c)} with the arguments \texttt{(a, b)}. The arguments \texttt{a} and 
    \texttt{b} are pushed onto a new closure object, which contains a function 
    pointer to \texttt{g} and a pointer to the previous closure object. When 
    \texttt{cl\char`_g} is called with an argument \texttt{c}, \texttt{g} will 
    obtain \texttt{a} and \texttt{b} from the closure object and pass them 
    together with \texttt{c} to \texttt{f}.}
    \label{fig:partial-app}
\end{figure}

\subsubsection{Chaining partial applications}

An important requirement is that a partially applied closure needs to act the
same as an unapplied closure, as in we must be able to partially apply it again.
This requirement is the justification for why closures are implemented as 
a linked list -- each closure needs to know the function pointer of the next 
function they need to invoke, but that isn't always possible to determine 
statically\footnote{As an example, consider a partially applied function which 
is passed as an argument to a higher-order function, which further partially 
applies the function.}.

Thus, each closure resulting from partial application points to the closure from
which it was derived from so their function can figure out what function pointer
to invoke (see figure \ref{fig:partial-app}).

\begin{figure}
    \centering
    \input{./figs/double_partial_app.tex}
    \caption{Example of a chained double application. In this case, the 
    function \texttt{f(a, b, c)} has been applied with \texttt{a} and 
    \texttt{b} separately, creating two closure objects, \texttt{cl\char`_g} in 
    the first application, and \texttt{cl\char`_h} in the second. Here, 
    \texttt{h} translates a call \texttt{h(c)} into \texttt{g(b, c)}, which in 
    turn translates that call into \texttt{f(a, b, c)}.}
    \label{fig:double-partial-app}
\end{figure}

\subsection{Lexical closure compilation}

Lexical closures are another common use of closures, and occur when a function
refers to values in an enclosing scope. This presents a problem in C, as it does
not allow nesting functions.

Because our closure representation allows storing arbitrary data already, this
is simple to implement using closure objects. When compiling any local function,
first check if the function contains any free variables. If it does, take the
value of all the free variables at that point and push them onto the closure
object, and when compiling the function body, before compiling re-assign all
lexically bound variables to values from the closure object.

As an example, consider the compilation of the following OCaml 
code:\footnote{In an actual compilation, this will get eta-expanded to make the 
function types consistent (see \S\ref{incomplete-funcs}) but we suppose 
this doesn't happen in this example for simplicity.}

\begin{lstlisting}[language=Caml]
let f x y =
    let g z = x + y + z in g
\end{lstlisting}

This is compiled into the following C-style pseudocode:

\begin{lstlisting}[language=C]
int f(int x, int y, closure_type* closure_obj) {
    closure_type* cl_g = MALLOC(sizeof(closure_type) + sizeof(any_type)*2);
    cl_g->f = &g;
    cl_g->next = NULL;
    cl_g->data[0] = x;
    cl_g->data[1] = y;
    
    return cl_g;
}

int g(int z, closure_type* closure_obj) {
    int x = closure_obj->data[0];
    int y = closure_obj->data[1];
    
    return x + y + z;
}
\end{lstlisting}

\subsection{Parametric polymorphism}

Parametric polymorphism is an important feature in OCaml, allowing programmers
to write general code without knowing the type of its arguments in advance. As
discussed in \S\ref{value-repr} we use the \verb|value_type| representation of
polymorphic values when defining polymorphic functions.

This works fine for passing simple values and polymorphic datatypes, as long as 
we remember to cast values to \verb|value_type| when passing values to 
polymorphic functions, and cast back to their actual types when receiving 
values from function calls.

However, passing other functions (closures) into polymorphic functions is more 
problematic.

\subsubsection{Erasing function types}

When passing a non-polymorphic function, e.g. \texttt{float -> float}, to
polymorphic function expecting an \texttt{'a -> 'b} requires a cast between the
two types. This is because the polymorphic function is representing \texttt{'a}
as \verb|value_type|, and so will attempt to pass data of the type
\verb|value_type| into the function, and will expect a return type also of
\verb|value_type|. Thus in order to cast \texttt{float -> float} we will need to
add a wrapper function which performs the casts.

\begin{lstlisting}[language=C]
value_type g(value_type x, closure_type* closure_obj) {
    double new_x = UNBOX_FLOAT(x);

    closure_type* cl = closure_obj->next;
    double result = cl->f(new_x, cl);
    
    value_type new_result = BOX_FLOAT(result);
    return new_result;
}

closure_type* cl_g = MALLOC(sizeof(closure_type));
cl_g->f = &g;
cl_g->next = cl_f;
\end{lstlisting}

This in fact needs to happen any time it's possible to ``lose track'' of the
actual type of a function, i.e. it's possible the function will be used in a
situation where its type has been generalised away. This includes adding
functions to an OCaml block (because the data structure may be passed to a
function polymorphic in a subtype of the data structure), or accessing functions
from an OCaml block\footnote{It's not safe to simply remove the head from the
    closure chain to undo this cast, as there's no guarantee the last
    transformation applied to a closure will the cast -- the closure may have
been partially applied or cast again to something else.}, or storing and
retrieving functions from closure data.

Thus, the casting rules from \S\ref{casting} need to be modified.

\begin{enumerate}

\item If the source type is \verb|value_type| or \verb|any_type|, when casting
    back assume all of its argument and return types are \verb|value_type|, and
    then cast it back to the expected type using the technique from the previous
    section.

\item If the target type is \verb|value_type| or \verb|any_type| and the source
    type is a function, first erase types from that function by rewriting all
    its argument and return types to \verb|value_type| using the technique from
    the previous section before proceeding with the cast.

\end{enumerate}

\subsubsection{``Upcasting'' functions}

Another case when dealing with polymorphic functions is when the expected type
of a function has fewer parameters than the actual type, e.g.  passing a
function of type \texttt{float -> float -> float} to a higher-order function
that is expecting a \texttt{'a -> 'b}. This poses a problem for the type system
for functions we decided on in \S\ref{function-typing}.

To see why, consider a polymorphic function which receives a function 
\texttt{'a -> 'b}, and needs to apply it to something of type \texttt{'a}. How 
does it know whether to treat this as a full application, where it needs to 
invoke the function as a closure, or a partial application, where it needs to 
create a new closure object?

One solution is to solve this on the caller's side. Essentially, we want to
transform a C function signature from:

\begin{lstlisting}[language=C]
value_type f(value_type x, value_type y, closure_type* closure_obj);
\end{lstlisting}

into\footnote{The \texttt{closure\char`_type*} is actually also cast into a 
\texttt{value\char`_type}, to match the type the polymorphic function is 
expecting.}:

\begin{lstlisting}[language=C]
closure_type* g(value_type x, closure_type* closure_obj);
// where the returned value points to the function
value_type h(value_type y, closure_type& closure_obj);
\end{lstlisting}

This is to ensure that from the point of view of a polymorphic function, if the 
same number of elements is applied to the function type, then it can be 
considered fully applied.

This transformation can be modelled using the current closure representation,
using a process I refer to as ``upcasting''. In this process of upcasting a
function \texttt{f}, two more functions are created, which are \texttt{g} and
\texttt{h}.

\texttt{g}'s role is to act as the resulting function that will be passed into
whatever polymorphic function. It's essentially a wrapper around a partial
application.

\begin{lstlisting}[language=C]
closure_type* g(value_type x, closure_type* closure_obj) {
    closure_type* cl = MALLOC(sizeof(closure_type) + sizeof(any_type));
    cl->f = &h;
    cl->next = closure_obj;
    cl->data[0] = x;
    
    return cl;
}
\end{lstlisting}

\texttt{h} acts as the counterpart function to a polymorphic function, which 
takes the data that \texttt{g} has set up for it and applies it to \texttt{f}.

\begin{lstlisting}[language=C]
value_type h(value_type y, closure_type* closure_obj) {
    value_type x = closure_obj->data[0];
    
    closure_type* cl = closure_obj->next;
    value_type result = cl->f(x, y, cl);
    
    return result;
}
\end{lstlisting}

The surrounding code adds \texttt{g} as a closure onto \texttt{f}'s closure.

\begin{lstlisting}[language=C]
closure_type* cl_g = MALLOC(sizeof(closure_type));
cl_g->f = &g;
cl_g->next = cl_f;
\end{lstlisting}

By tracing through the executions, it can be seen that an application by 
\texttt{x} followed by an application by \texttt{y} gives the correct function 
call \texttt{f(x, y)}.

\section{Garbage Collection} \label{gc}

We can use the Boehm GC to implement a garbage collector without needing to
write one ourselves. Because of the way we have defined the implementation of
OCaml values, all values potentially representing pointers will be unchanged in
their actual binary value. This means that we can simply ``drop-in'' the Boehm
GC by including the following in our runtime:

\begin{lstlisting}[language=C]
#include "gc.h"
#define MALLOC(v) GC_MALLOC(v)
\end{lstlisting}

\chapter{Evaluation}

The resulting compiler was evaluated in two key aspects, which are the 
resulting speed of the produced executables and the observability of the debug 
output.

\section{Regression tests and feature completeness}

To test the correctness of the compilation, over the course of the project 21 
different regression tests were written to test different features of the 
language were being compiled correctly. They include simple tests which test 
one feature each, to more complex tests which test multiple features combined 
in different variations.

With every iteration of the compiler, regression tests are run against it to 
ensure that the output of the compiler remains correct. To do this, a simple 
regression test script was written which compiles the same OCaml program 
against the OCaml native compiler and my compiler, and asserts that the output 
of both executables match.

One of the most complex regression tests is one which reimplements many of the 
list processing functions in the OCaml standard library. These functions use 
many advanced features of the language, including recursion, pattern matching, 
parametric and datatype polymorphism, and closure creation.

\section{Benchmarks}

A most natural way to evaluate the compiler is to compare the execution times 
of the output, and the most natural metric to compare the compiler against is 
the existing OCaml compiler. The basic idea of all the benchmarks is simple -- 
it's to compile the same program under the OCaml standard compilers and under 
my compiler, and compare the execution speed of their outputs.

Several different configurations for comparisons can be attempted. OCaml 
supplies two compiler backends, the OCaml native compiler (\texttt{ocamlopt}) 
and the OCaml bytecode compiler (\texttt{ocamlc}). For our purposes, we will be 
mostly considering the output of the native compiler, as the bytecode 
interpreter unsurprisingly is at least one order of magnitude slower than the 
native compiler.

In addition, since my compiler only produces C code, we have a choice as to 
which compiler to compile the C code with, and under which configurations. I 
chose the most popular C compilers, \texttt{gcc} and \texttt{clang}, and 
compiled the code under the four optimisation levels provided (\texttt{-O0}, 
\texttt{-O1}, \texttt{-O2}, and \texttt{-O3}).

To simplify the process of running the many benchmarks against the
configurations, a script \texttt{run\char`_benchmarks.py} was written, and the
results were plotted using Python and matplotlib.

\subsection{Sourcing Benchmarks}

Benchmarks programs were taken from the Computer Language Benchmarks Game 
(CLBG)\cite{benchmarks-game}, the \texttt{operf-micro}\cite{operf-micro} OCaml 
library, and the rest were written by me.

These programs were chosen to exemplify a wide range of features within the 
OCaml language, particularly to exercise the more advanced features of the 
subset of OCaml which I am targeting.

Benchmarks were adjusted to take between 0.5 to 2.0 seconds to run so that the 
timer does not significantly affect the running time, and were run 50 times 
each on an idle Linux laptop.

\begin{figure}
    \centering
    \resizebox{\textwidth}{!}{
        \includegraphics{figs/raw_benchmarks.pdf}
    }
    \caption{Execution times for comparison between the OCaml native compiler 
    (\texttt{ocamlopt}), and the C compilers at the highest optimisation level. 
    Execution times were normalised with respect to the OCaml bytecode 
    compiler, setting the execution time of the compiled bytecode to be 1.0. 
    Error bars represent 1 standard deviation in the execution time.}
    \label{fig:raw-benchmarks}
\end{figure}

On the whole, C compilers do quite well in comparison to the OCaml native 
compiler being only a small constant factor time slower in most cases and 
matching and outperforming the native compiler in select cases. Also of note 
was that in all benchmarks, the C compilers outperformed the OCaml bytecode 
compiler, which is surprising since no significant effort was made into 
optimisation of the C output.

A breakdown of the benchmarks is included below:

\begin{itemize}
    \item \texttt{binary-trees} is adapted directly from the CLBG, and is a 
    benchmark for garbage collection.
    
    \item \texttt{collatz} is a benchmark written by me, where the longest 
    Collatz chain is found between 0 and an upper limit using a tail-recursive 
    function.
    
    \item \texttt{even\char`_fib} and is composed of mainly a simple 
    tail-recursive function.
    
    \item \texttt{fibonacci} is a benchmark written by me, and performs 
    non-tail-recursive recursion.
    
    \item \texttt{lens} is a benchmark adapted from the \texttt{operf-micro} 
    library, and uses Haskell-like lens objects to perform calculations on a 
    rectangle record type. This benchmark performs plenty of closure operations 
    and therefore is a test of the speed of closures.
    
    \item \texttt{mandelbrot} is adapted directly from the CLBG, and is a 
    benchmark for imperative-style floating point manipulation.
    
    \item \texttt{n-body} is adapted from the CLBG with minor changes as it 
    requires arrays, which were not part of the target subset for my compiler. 
    It is a test for floating point operations in a more functional style.
    
    \item \texttt{rule30} is a benchmark written by me, the focus of this 
    benchmark being list manipulation and allocation and deallocation of lists.
    
    \item \texttt{sieve} is a benchmark taken from \texttt{operf-micro}, and 
    performs list manipulation via a tail-recursive function.
    
    \item \texttt{stream} is a benchmark written by me, and is heavy in both 
    custom in data manipulation, and closure creation and application.
    
\end{itemize}

Notable results from the benchmark include:

\begin{itemize}
    \item The drop-in garbage collection is unsurprisingly much slower than the 
    OCaml GC, as it is a conservative GC and does not have any domain-specific 
    knowledge. This can be best seen in the \texttt{n-body} benchmark.
    \item The C compilers perform extremely well on benchmarks that involve few 
    allocations and straightforward tail-recursive code, often beating even the 
    OCaml native compiler. This is seen in the \texttt{collatz}, 
    \texttt{even\char`_fib}, and \texttt{sieve} benchmarks.
    \item Strangely, the C compilers perform exceptionally bad in benchmarks 
    involving floating point manipulations, as can be seen in 
    \texttt{mandelbrot} and \texttt{nbody} benchmarks.
    \item Benchmarks which involve lots of closure creation and application are 
    also slower relative to the OCaml native compiler, as can bee seen in the 
    \texttt{lens} and \texttt{stream} benchmarks.
    \item In the \texttt{sieve} benchmark, the executable compiled with 
    \texttt{gcc} actually segfaults, the cause of which is a failure to perform 
    a tail-call optimisation.
\end{itemize}

\subsection{Investigating performance differences}

\subsubsection{Instrumentation}

Having obtained execution times for the different benchmarks, a natural 
question to ask is why the the OCaml and C compilers perform the way that they 
do; we would like some way of profiling the code to see what parts of the code 
take longer to run.

Fortunately, a key consequence of the compiler being from OCaml to C is that 
standard C tools will work on the resulting code, including Gprof, a profiler 
which can be enabled in \texttt{gcc} with the \texttt{-pg} flag. Gprof can 
provide information as to how much time is spent in each function via the flat 
profile, as well as information about how the call graph, or which functions 
called what other functions and how many times.

It turns out that OCaml also supports using Gprof to profile its native code 
output simply by adding the \texttt{-p} flag to \texttt{ocamlopt}, giving us a 
convenient way to compare the execution of the C executable and the OCaml 
native executable. We can therefore use this profiler to investigate 
performance differences between the OCaml native compiler and the C compiler.

\subsubsection{Floating point and polymorphic structures} \label{float-alloc}

For example, one discrepancy which we may wish to investigate is the 
\texttt{mandelbrot} benchmark, which C compilers perform much worse on despite 
having been written in imperative-style code.

\begin{figure}
    \centering
    \input{figs/mandelbrot_gprof.tex}
    \caption{Truncated Gprof outputs for the OCaml native executable and the C 
    executable, which has been highlighted with the roles of each function. 
    Functions highlighted green are logical functions for the execution of the 
    program, functions highlighted red are to do with allocating blocks on the 
    heap, and functions highlighted blue are functions used by the garbage 
    collector.
    Note that compiling with profiling information inserts extra instructions 
    and function calls for instrumentation purposes so the times shown are not 
    indicative of how fast the benchmarks execute otherwise.}
    \label{fig:mandelbrot-gprof}
\end{figure}

I collected profiling information using Gprof from both the native and C 
executables, a truncated version of which can be seen in figure 
\ref{fig:mandelbrot-gprof}. As shown below, the OCaml executable spends almost 
100\% of its execution time in the main logic of the program (which is the 
\texttt{entry} function), in comparison to the C executable, which only spends 
44.37\% of the execution time in the main logic. Instead, the majority of the 
time spent during execution is allocating new blocks and garbage collecting old 
ones.

Upon further investigation, it was found that the \texttt{mandelbrot} benchmark
stored \texttt{float}s inside \texttt{float ref}s, and the \texttt{Lambda}
representation normalises references into singleton OCaml blocks. This means
that according to the casting rules as described in \S\ref{casting}, whenever a
\texttt{float} needs to be stored inside a \texttt{float ref} a new tagged OCaml
block is allocated on the heap and then the pointer is stored in the
\texttt{float ref}. This means that mutable floating point fields within OCaml
blocks are in fact incredibly slow, as each store necessitates creating a new
block on the heap, and needing to GC the block that was replaced.

The same is true for the \texttt{nbody} benchmark, which uses mutable float 
fields in a record to store the position, velocity, mass etc. of the different 
celestial bodies.

\subsubsection{``Reduced allocations'' mode}

This problem means that floating point operations become incredibly slow, but 
it is necessary for observability, as non-integral or pointer types may be 
tagged with their type within polymorphic structures so that a debugger is able 
to infer their types. If we relax this requirement however, since the OCaml 
runtime does not require data to be tagged with their type (as the code has 
already been type-checked), we can store floating point numbers (and other 
types, such as closures and strings) directly within OCaml blocks without 
needing to make a separate object on the heap to tag their types.

\begin{figure}
    \centering
    \resizebox{\textwidth}{!}{
        \includegraphics{figs/benchmarks-no-alloc.pdf}
    }
    \caption{Execution times for comparison between the OCaml native compiler 
    (\texttt{ocamlopt}), and the C compilers at the highest optimisation level, 
    but with the reduced allocations flag enabled. While most of the benchmarks 
    do not change much, note that the execution times for \texttt{mandelbrot} 
    and \texttt{nbody} decrease signficantly.}
    \label{fig:benchmarks-no-alloc}
\end{figure}

I implemented this mode which is accessible via a C compiler flag, and obtained 
results which demonstrated far more favourable execution times especially for 
the \texttt{mandelbrot} and \texttt{nbody} benchmarks, as can be seen in figure 
\ref{fig:benchmarks-no-alloc}.

While this change does increase the performance of the compiler, it is worth 
noting that this means that polymorphic structures are no longer observable as 
a debugger cannot determine all the types at runtime, as well as meaning that 
functions that require some degree of runtime reflection such as OCaml's 
polymorphic comparisons do not function. This means that while the results 
provided by this mode are interesting and represent the performance of the 
compiler under perhaps a better representation of polymorphic data, it is not 
suitable for use generally.

\subsubsection{Tail recursion} \label{tail-recursion}

Another interesting question to ask is if the C compilers can see through the 
closure representation to perform tail-call optimisation, since it is far more 
idiomatic to write tail-recursive functions in OCaml than it is to write 
explicit iteration. It is therefore important for performance that the C 
compilers can do tail-call optimisation to avoid the extra overheads of 
function calls as well as avoiding stack overflows.

To do this, we can use the \texttt{objdump} Linux utility, which can 
``disassemble'' the executable, printing out the assembly mnemonics 
corresponding to the machine code.  Figure \ref{fig:tail-recursion} shows the 
disassembly of the following simple tail-recursive function:

\begin{lstlisting}[language=Caml]
let rec add x y =
  if y = 0 then
    x
  else
    add (x - 1) (y + 1)
\end{lstlisting}

As can be seen, the C compiler is able to infer that the closure application is 
equivalent to a function call in tail-call position, despite not being able to 
see through the closure representation explicitly, and has therefore compiled 
the closure application into a single \texttt{jmp} instruction. This means that 
tail-recursive functions do not incur the full penalties from a function call, 
but a small amount of overhead from needing to load in an address

\begin{figure}
    \centering
    \input{figs/tail_recursion.tex}
    \caption{Disassembly of the the function \texttt{let rec add x y = if y = 0 
    then x else add (x - 1) (y + 1)} compiled using my compiler and then using 
    \texttt{gcc -O3}. The compiler is able to optimise the tail call, but is 
    not able to see through the closure representation to optimise into a loop, 
    instead jumping to a function pointer obtained via the closure object (the 
    pointer to which is initially stored in the \texttt{rdx} register).}
    \label{fig:tail-recursion}
\end{figure}

\subsubsection{Stack overflow} \label{stack-overflow}

On the \texttt{sieve} benchmark, the \texttt{gcc} executable compiled under all 
optimisation levels segfaults, which is because of a stack overflow. This is 
particularly confusing because the \texttt{sieve} benchmark was written to be 
tail-recursive, and also the executable produced by \texttt{clang} does not 
segfault, indicating that \texttt{clang} must have been able to perform the 
tail-call recursion.

After some investigation, the offending code was found to be this:

\begin{lstlisting}[language=C]
typedef union {
    void* ptr;
} val;

void* g(val);

val f(val x) {
    return {.ptr = g(x)};
}
\end{lstlisting}

When compiled with gcc, this produces the rather confusing output:

\input{figs/stack_overflow.tex}

Somehow, the cast back into the union type prevents \texttt{gcc} from detecting 
the function call is in tail-call position in this specific case, despite the 
fact that the resulting machine code could obviously be optimised and the 
function call be put in tail-call position.

\subsubsection{Closure creation}

For a lot of benchmarks the C compilers perform far worse than the OCaml native 
compiler which is likely to be due to the fact that the closure operations in C 
are far slower than the OCaml native compiler can compile them.

To confirm this, I collecting profiling information from the \texttt{lens} 
benchmark, which is perhaps the most heavy benchmark in terms of closure 
creation and application. The truncated flat profiles can be seen in figure 
\ref{fig:closure-creation}.

\begin{figure}
    \centering
    \input{figs/closure_creation.tex}
    \caption{Truncated Gprof outputs from the \texttt{lens} benchmark, coloured 
    using the same scheme as before in figure \ref{fig:mandelbrot-gprof}, with 
    the addition of yellow functions being related to the closure 
    creation/application process.}
    \label{fig:closure-creation}
\end{figure}

As can be seen by the results, the execution time of the C executable is 
strongly dominated by the garbage collector and functions used in the process 
of closure creation and application, with functions implementing logic actually 
being a small fraction of the execution time. This is in strong contrast to the 
OCaml code, where the run time is dominated instead by the actual logic of the 
program and the printing functions.

This suggests that in certain workloads the closure representation can degrade 
the performance significantly, resulting in unnecessary amounts of work being 
put into closure operations as compared to if the compiler was able to see 
through them. Furthermore, since the closure operation necessitates allocating 
new blocks onto the heap, creation of lots of closures can put much more extra 
stress onto the garbage collector.

These problems may be allayed with a better closure representation, for example 
turning partial application into generating function stubs which push the 
correct arguments into the correct registers before jumping to the function 
body. Unfortunately, there was insufficient time to investigate more performant 
closure representations.

\begin{figure}
    \centering
    \resizebox{\textwidth}{!}{
        \input{figs/benchmark_table.tex}
    }
    \caption{Summary results of benchmark results. All figures given in 
    seconds.}
\end{figure}

\section{Observability}

The other way to evaluate the the compiler is to determine the observability of 
the compiled output, or how much information we are able to recover about the 
internal state of the program as it is executing.

The OCaml native code compiler can be said to be not observable at all, since 
the native executables do not support debugging. Instead, comparisons will be 
made with the OCaml bytecode debugger.

\subsection{Sample GDB session}

We consider the following simple program, for summing a list of numbers using a 
generic fold function.

\input{appendices/sum_prog.tex}

Debug sessions when debugging using both GDB and \texttt{ocamldebug} can be
found in appendix \S\ref{debug-sessions}, with equivalent commands entered
for both sessions. There are some minor differences with regards to which
locations the debuggers stop at, and the commands have been altered slightly to
reflect this.

By loading in a script which enables custom pretty-printers, we are able to 
observe OCaml values in a nicer representation than printing out raw pointers. 
In addition, the use of \texttt{\#}\texttt{line} directives has meant that that 
GDB can display correctly the lines of OCaml code the code it is currently 
debugging correspond to, allowing breakpoints to be set. Since what is being 
debugged underneath is essentially just a C program, the full power of GDB's 
tools can be utilised, including breakpoints, backtraces, watchpoints, etc.

\subsection{Identifiers}

In the C code, in order to avoid ambiguity we suffix identifier names with 
their unique `stamp' in order to avoid naming conflicts. Practically, this is 
more of an annoyance than a problem. As GDB allows tab completion in order to 
reference variable names, to obtain the name of a variable in the C code one 
only needs to type the name followed by an underscore, then press tab to 
tab-complete the appropriate stamp.

This does however mean that debugging is a worse experience in comparison to
\texttt{ocamldebug}, where typing the name of a variable automatically refers to
the variable with that name which is currently in scope. Because of the
precautions outlined earlier in \S\ref{variable-scoping}, it should not be
theoretically difficult to erase these `stamps' from variable names, but
practically there are a few problems with this:

\begin{itemize}
    \item The \texttt{Lambda} IR introduces new variables in certain cases, but 
    does not care about naming conflicts as its transformation is 
    post-source-code level where identifiers are compared using their stamps 
    only. This means that erasing stamps naively would cause naming conflicts.
    \item There is no equivalent way to deal with this for top-level 
    identifiers, as we cannot have shadowing in the top-level scope in C.
\end{itemize}

\subsection{Polymorphic printers}

The \texttt{debug/pprint.py} script is a script written to enable printing of 
OCaml values within GDB, as otherwise many values will only be displayed as 
pointers otherwise.

This is a point where my implementation performs better than 
\texttt{ocamldebug}. Because of the representation strategy described in section
\ref{value-repr}, we can determine the types of values at runtime even if the 
code we're debugging does not know the types themselves.

We can see this at lines 24-31 in the GDB output (\ref{debug-gdb}), and 
lines 10-15 in the \texttt{ocamldebug} output (\ref{debug-ocaml}). The 
pretty printers which I have loaded into GDB are correctly able to infer that 
the values being printed are integers and an integer list, but 
\texttt{ocamldebug} cannot, and instead can only print the polymorphic values 
as \texttt{<poly>}.

One limitation of this however is that when printing data structures, I print 
the in-memory representation of the structure instead of how it would be 
represented in OCaml. Had I more time this could be remedied by also outputting 
a lookup table for the pretty printers to use to find out what type a data 
structure is and how it should be formatted. As of currently, OCaml blocks are 
printed with the tag first, a colon, and then the data within the block; this 
results in the list \texttt{[1; 2; 3]} being printed as \texttt{[0: 1 [0: 2 [0: 
3 0]]]}.

\subsection{Line number matching}

While the line number matching between the C code and the OCaml code is 
acceptably good for debugging, there are certain cases which it does fall down, 
due to a fundamental difference in the way GDB and \texttt{ocamldebug} treats 
points where the debugger may pause execution.

\texttt{ocamldebug} notably only pauses at \texttt{Lambda} events, which are
described in \S\ref{levents}, but GDB only pauses on lines of code. Since
\texttt{Lambda} events are inserted directly before or after certain
expressions, \texttt{ocamldebug} is able to pinpoint exactly where in the
evaluation of the code it has stopped, but GDB is unable to do this, only
printing the line of code where it stops at.

This is especially confusing for sometimes for local anonymous functions. For 
example, in the \texttt{sum} example from earlier, stepping inside the 
\texttt{(f acc x)} expression on line 5 steps you back to the line 8 
(\texttt{let sum = foldl (+) 0}), because we are stepping inside the implicitly 
defined \texttt{(+)} function, which was defined on line 8.

\chapter{Conclusion}

Overall, the project was largely successful as I had accomplished my goal of 
compiling the target subset of OCaml correctly into C, as well as providing 
facilities under which the resulting C code could be ``observed'' by a debugger 
as if it was OCaml code.

Translations of technically challenging features of the languages such as data 
representation and closure represented were attempted, and largely successful. 
My implementation also leaves room for further additions to the compiler to add 
support for the remaining features of OCaml which were not included in the 
target subset if more time was to be dedicated.

We can see that the motivations of the project have been largely fulfilled, 
including:

\subsubsection{Observability}
The work into making the code observable has largely held up, with GDB being 
able to display the current location of the code and observe OCaml values, even 
polymorphic values that the \texttt{ocamldebug} debugger could not discern. It 
is a weak point however that GDB is unable to print out OCaml data structures 
using OCaml's notations for them, but this is very possible with an extension 
to the compiler that generated debug information for the types of objects 
within the executable being debugged.

\subsubsection{Plausibility}
The completion of the compiler is a proof that my approach to compiling OCaml 
and other similar languages into C works, and it is possible to represent even 
complex closure structures and OCaml's algebraic data types within C, as well 
as a debugger being able to ``see through'' parametric polymorphism to 
determine the types of the values being manipulated.

\subsubsection{Performance}
Despite no heavy efforts being paid to make the resulting code performant, 
under all tested workloads my compiler outperforms the OCaml bytecode compiler 
and matches or is sometimes even faster than the OCaml native compiler in 
select workloads.

My project leaves plenty of room for future extension work, and there are 
things that I would've done differently had I started the project again. These 
include:

\begin{itemize}
    \item Support for OCaml's module system, allowing multi-file programs to be 
    compiled correctly. Currently the compiler is only capable of compiling one 
    file at a time, but it should not be difficult extend this support;
    \item Support for more of OCaml's standard library, allowing standard 
    library modules to be compiled and used;
    \item Support for a larger subset of OCaml's core language, including array 
    types and a better support for floating point values, in order to make them 
    more performant;
    \item A key assumption of the code is that all primitive types needed are 8 
    bytes long, or word-sized on a 64-bit system. It would be nice if less 
    reliance was depended on this so the compiler was more portable to other 
    systems than 64-bit Linux;
    \item More performant closures, such as generating function stubs at 
    runtime to implement closure operations, or using a closure implementation 
    from a popular library such as \texttt{libffi};
    \item More time spent with libraries, such as my supervisor's 
    \texttt{liballocs}, in order to make it possible to have runtime reflection 
    without resorting to less performant means of storing values.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the bibliography
\addcontentsline{toc}{chapter}{Bibliography}

\begin{thebibliography}{9}

\bibitem{noassemblyrequired}
D. Tarditi, A. Acharya, P. Lee,
\textit{No Assembly Required: compiling Standard ML to C},
November 1990.\\
\url{http://repository.cmu.edu/cgi/viewcontent.cgi?article=3011&context=compsci}

\bibitem{previousproject}
C. Sun,
\textit{An Observable OCaml with liballocs and C},
May 2017.

\bibitem{realworldocaml}
A. Madhavapeddy, J. Hickey, Y. Minsky,
\textit{Real World OCaml},
O'Reilly Media,
November 2013.

\bibitem{liballocs}
S. Kell,
\textit{Towards a Dynamic Object Model within Unix Processes},
October 2015.

\bibitem{benchmarks-game}
CLBG,
\textit{The Computer Language Benchmarks Game},
last accessed at 2018-03-26.\\
\url{https://benchmarksgame.alioth.debian.org}

\bibitem{operf-micro}
OCamlPro,
\textit{A set of micro-benchmarks for OCaml compiler},
last accessed at 2018-03-26.\\
\url{https://github.com/OCamlPro/operf-micro/}

\end{thebibliography}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the appendices
\appendix

\chapter{Implementation Details}

This appendix chapter provides some more details about finer implementation
details that could not fit within the implementation chapter.

\section{The \texttt{Ccode} module} \label{ccode}

The \texttt{Ccode} module stores the OCaml representation of the target C
subset. It is specially chosen to be a subset of C, and only contain the
necessary types to represent the compilation target. There are four main
datatypes in the module, and a quick summary of them is given here:

\begin{itemize}

\item \texttt{Ccode.cident}, for representing identifiers (variable names, macro
    names, function names etc.) in C. This is largely a wrapper over the
    \texttt{Ident.t} type the OCaml compiler uses to represent identifiers,
    which is the string name along with a unique integer ID to disambiguate it
    from other identifiers with the same name.

\item \texttt{Ccode.cexpr}, for representing expressions in C. These include a
    wrapper around \texttt{cident}s, literals, and operations (such as unary
    operations, binary operations, function calls etc.) on other
    \texttt{cexpr}s.

\item \texttt{Ccode.cstatement}, for representing statements in C. Most data
    constructors in this type take a \texttt{cexpr} or a block of other
    \texttt{cstatement}s, and include if statements, while statements, switch
    statements etc. Notably a \texttt{cexpr} can be promoted to a
    \texttt{cstatement}, but not the other way around.

\item \texttt{Ccode.ctype}, for representing types in C. This is a auxiliary
    type used by the casting operator in \texttt{cexpr} and the variable
    declaration statement in \texttt{cstatement}. A more in-depth discussion of
    the types used to represent OCaml values is at \S\ref{value-repr}.

\end{itemize}

In addition, the \texttt{Ccode} module contains some special record types:

\begin{itemize}

\item \texttt{Ccode.cfunc}, which is a record type holding information about the
    return type of the function, the names and types of its arguments, its name,
    its body of code, and its location in the source.

\item \texttt{Ccode.ccode}, which is the record struct that is finally passed
    into \texttt{Cprint} to print the code. It is composed of three lists: the
    block of statements that forms the preamble (which is things like
    \texttt{\#}\texttt{include} directives and global variable declarations),
    the list of functions, and the block of code representing the \texttt{main}
    function.

\end{itemize}

\section{Purpose of \texttt{runtime.h}}

\texttt{runtime.h} is a special header file which needs to be included in the
compilation of the output C file to produce executables from my compiler. It
contains the type declarations mentioned in the implementation chapter, as well
as helper functions and macros useful for implementing certain structures and
observability features.

\section{\texttt{\#}\texttt{line} directives} \label{line-directive}

A key observability feature is for the debugger to associate the currently
executing machine code with the relevant line from the source.

C compilers support controlling the line and source file of your code with use
of the \texttt{\#}\texttt{line} directive. This means the compiler can put all
statements associated with one line of source on the same line\footnote{the line
    number changes whenever there is a new line, even after being specified with
\texttt{\#}\texttt{line}.}, interspersed with a \verb|#line| directive whenever
the source code line actually changes.

To actually obtain information about which line we're on, we again use
\texttt{Lambda} events (\S\ref{levents}), as they carry information about the
current file and line. Since they also represent places where the OCaml bytecode
debugger \texttt{ocamldebug} may pause execution, this gives us a pleasing way
to treat them: \texttt{Lambda} events simply compile directly into \verb|#line|
directives.


\section{Compilation of basic constructs} \label{basic-constructs}

This section gives an overview of other common basic syntactical structures
in OCaml are compiled into C.

\subsection{Variable scoping differences between C and OCaml}
\label{variable-scoping}

In OCaml, each variable is only visible in the body of the expression where it
is bound, whether if that's in a let-binding or a function declaration. This is
in contrast to variable scope in C, where a variable is visible for the entirety
of the rest of the block it is in.

Furthermore, while OCaml does not allow reassignments (of variables, not 
references), it does allow you to bind another variable with the same name:

\begin{lstlisting}[language=Caml]
let x = 1 in
let x = 2 in
print_int x
\end{lstlisting} 

Here the second binding is not reassigning the value of \texttt{x}, rather it's 
creating another variable with the same name. The first variable still exists, 
but it's been shadowed by the second variable making it inaccessible. Note that 
after leaving the body of the second let binding the second variable goes out 
of scope and the first variable is accessible again.

This behaviour can be approximated using C99's block-scoping:

\begin{lstlisting}[language=C]
int x = 1;
{
    int x = 2;
    print_int(x);
}
\end{lstlisting}

Here we see that within the inner block, the second declaration of \texttt{x}
has shadowed the first declaration of \texttt{x}, but the original declaration
of \texttt{x} is still accessible once we leave the inner block (which is also
the behaviour in OCaml). Therefore, we have to pay careful attention to
inserting variable scopes to correctly mirror the shadowing effects in
OCaml\footnote{Note however we cannot apply this process for variable
    declarations at the top-level, since you cannot insert block-scopes at the
    top level in C. Unfortunately this requires top-level variables to be
renamed.}.

\subsection{Meta-notation for compilation} \label{meta-notation}

To describe the compilation process from OCaml expressions into C we use a
C-like meta-notation. Recall from \S\ref{expr-stmt}, each OCaml expression
compiles to a set of C statements and a variable, which the C statements will
have assigned the correct value to after their execution. We therefore denote
the set of C statements an expression \textit{\texttt{e}} compiles into as
\texttt{comp<\textit{e}>}, and the variable it is associated with with
\texttt{var<\textit{e}>}. This gives a way of recursively defining the
compilation process by defining \texttt{comp<\textit{e}>} for all possible OCaml
expressions. In the actual compiler, the \texttt{comp<>} functions are
implemented within the \texttt{Ccompile} module, which outputs an equivalent
representation of C using the types in the \texttt{Ccode} module.

As an example, consider the OCaml expression \texttt{\textit{e1} + \textit{e2}}.
We therefore define:

\begin{lstlisting}
comp<$\textit{e1}$ + $\textit{e2}$> :=

declare$\footnotemark$ result;
comp<$\textit{e1}$>; // var<$\textit{e1}$> now contains the correct value
comp<$\textit{e2}$>; // var<$\textit{e2}$> now contains the correct value
result = var<$\textit{e1}$> + var<$\textit{e2}$>;
\end{lstlisting}
\footnotetext{\texttt{declare} here stands for the type of the result of the
expression which is required for variable declarations in C. In general, this
type is not known generally and depends on the specific types of the
subexpressions, so we use \texttt{declare} to stand in for this.}

\texttt{result} refers to some temporary variable name which we assign to this
expression, and we define \texttt{var<\textit{e1} + \textit{e2}> := result}.
Note that this is a common pattern so we will implicitly assume that when
defining the compilation of an expression \texttt{\textit{e}},
\texttt{var<\textit{e}>} will be the variable named \texttt{result} within
\texttt{comp<\textit{e}>}.

\subsection{\texttt{if-then-else} expressions}

OCaml does not have if-statements but if-expressions, which are of the form:

\begin{center}
    \texttt{if \emph{cond} then \emph{A} else \emph{B}}
\end{center}

Using the same notational conventions as in \S\ref{meta-notation}:

\begin{lstlisting}
comp<if $\emph{cond}$ then $\emph{A}$ else $\emph{B}$> :=

declare result;

comp<$\emph{cond}$>;
if (var<$\emph{cond}$>) {
    comp<$\emph{A}$>;
    result = var<$\emph{A}$>;
} else {
    comp<$\emph{B}$>;
    result = var<$\emph{B}$>;
}
\end{lstlisting}

The same trick to propagate results outwards from inner scopes has been 
employed here also.

\subsection{\texttt{while} loops}

While loops are fairly simple in OCaml -- they simply repeatedly evaluate their 
body while the condition evaluates to true. There are no break nor continue 
statements, so there is not a concept of breaking out of a loop early with the 
exception of setting the condition to false. They have the syntax:

\begin{center}
    \texttt{while \emph{cond} do \emph{body} done}
\end{center}

In addition, the overall return value of the loop is \texttt{unit}. The
compilation for them is therefore: 

\begin{lstlisting}
comp<while $\emph{cond}$ do $\emph{body}$ done> :=

comp<$\emph{cond}$>;
declare temp = var<$\emph{cond}$>;
while (temp) {
    comp<$\emph{body}$>;
    comp<$\emph{cond}$>;
}

declare result = make_unit();
\end{lstlisting}

There is one interesting thing of note here: \texttt{\emph{cond}} does need to 
be evaluated twice, once before the loop, and once at the end of the loop. This 
is because the OCaml while loop re-evaluates \texttt{\emph{cond}} at the 
beginning of each iteration, but since OCaml expressions turn into a list of 
statements in C, we cannot fit this re-evaluation into the head of the while 
statement -- instead, a simple and equivalent way around this is to simply 
re-evaluate \texttt{\emph{cond}} at the end of the loop.

\subsection{\texttt{for} loops}

For loops in OCaml are extremely limited. They permit only iteration over a 
fixed range of integers, and also only allow increments in steps of 1. Like 
with while loops, there are no break nor continue statements in OCaml and so 
there is no possibility of exiting a loop early. They have two forms, which are:

\begin{center}
\texttt{for \emph{x} = \emph{start} to \emph{end} do \emph{body} done}\\
\texttt{for \emph{x} = \emph{start} downto \emph{end} do \emph{body} done}\\
\end{center}

These two versions simply iterate up to or down to a certain number 
(inclusive). Since for loops are so incredibly limited, it was decided 
that rather than including for loops in the targeted subset of C, it would be 
easier to also compile these into while loops in C.

\begin{lstlisting}
comp<for $\emph{x}$ = $\emph{start}$ to $\emph{end}$ do $\emph{body}$ done> :=

comp<$\emph{start}$>;
comp<$\emph{end}$>;
int temp1 = var<$\emph{start}$>;
int temp2 = var<$\emph{end}$>;

{
    decl x = temp1;
    while (x <= temp2) {
        comp<$\emph{body}$>;
        x++;
    }
}

decl result = make_unit();
\end{lstlisting}

(Replace \texttt{<=} for \texttt{>=} and \texttt{x++} for \texttt{x--} for 
\texttt{downto}.)

There are a few things about this compilation that warrant elaboration:
\begin{itemize}

\item \texttt{\emph{x}} again needs to be declared in its own scope, as the for
    loop acts as another variable binding site. Thus, the entirety of the for
    loop is wrapped in another block.

\item Note the use of \texttt{temp1} and \texttt{temp2}, which are necessary
    because \texttt{var<\emph{start}>} and \texttt{var<\emph{end}>} may collide
    with the name of the variable \texttt{x} and cause it to be shadowed in the
    inner scope.

\item \texttt{\emph{start}} and \texttt{\emph{end}} are only evaluated once at
    the start of the loop -- after some quick experiments it could be shown that
    OCaml does this as well, i.e. the limits of the iteration range do not
    change while the loop is running.

\item \texttt{\emph{x}} is mutated through the iteration of the loop. This is
    fine, as OCaml for loops only operate on integers, which are copied instead
    of referenced by other constructs in the target subset of C; thus the
    mutation of \texttt{\emph{x}} cannot affect the behaviour of the program.

\end{itemize}

\section{Value representation details}

This section deals with details related to the value representation used in the
compiler.

\subsection{\texttt{Lstaticraise} and \texttt{Lstaticcatch}}

The \texttt{Lambda} IR also has support for static exceptions, which are
exceptions that can only occur across a local scope\footnote{In contrast to
normal exceptions, which unwind the stack and can jump to an error handler in an
enclosing scope.}. This is similar to the behaviour of a \texttt{goto} statement
in C. In particular, the OCaml pattern-match compiler may opt to use a static
exception to avoid duplication of code for certain branches. For example,
consider this match expression:

\begin{lstlisting}[language=Caml]
type color =
  | Red
  | Green
  | Blue
  | Gray of int
  | RGB of int * int * int

match c with
  | Red -> 0
  | Green -> 1
  | Gray x -> 2
  | _ -> 3
\end{lstlisting}

This match expression contains a wildcard expression which matches both 
\texttt{Blue}, which is an integer, and \texttt{RGB}, which is a block. The 
OCaml pattern-match compiler thus compiles it into the following 
\texttt{Lambda} expression:

\begin{lstlisting}
(catch
  (switch* c/xxxx
    case int 0: 0
    case int 1: 1
    case int 2: (exit 1)
    case tag 0: 2
    case tag 1: (exit 1))
  with (1) 3)
\end{lstlisting}

The branches for \texttt{Blue} and \texttt{RGB} have been compiled into a static
exception (the \texttt{exit} expression), to avoid duplicating the expression in
the branch. This behaviour can be emulated with \texttt{goto}s in C.
\texttt{Lstaticcatch} expressions can be compiled simply into an \texttt{if(0)}
and a label, and \texttt{Lstaticraise} expressions are simply compiled into a
\texttt{goto}.


\section{Closure details}

This section deals with details related to the compilation of functions and
closures.

\subsection{Functions that return other functions} \label{incomplete-funcs}

\S\ref{function-typing} provides a scheme for converting between function types
in OCaml to function types in C, but this conversion doesn't always make sense.
In OCaml, it is possible and often useful to define functions that return other
functions. As a simple example, consider the function:

\begin{lstlisting}[language=Caml]
let f x = (fun y -> x + y)
\end{lstlisting}

The type of \texttt{f} is \texttt{int -> int -> int}, but it's obvious that this
isn't translatable into a C function \texttt{int f(int x, int y)} -- the body of
the function would return a closure, and not an integer.

Since the type of \texttt{f} is known, this is a rather simple problem to fix
via a technique known as eta-expansion, and can be done at the source code
level. Simply add extra parameters to match the number of parameters in the
type, and apply them to the old result of the function.

\begin{lstlisting}[language=Caml]
let f x y = (fun y -> x + y) y
\end{lstlisting}


\chapter{Debug sessions} \label{debug-sessions}

\section{The ``sum'' program}

\input{appendices/sum_prog.tex}

\section{GDB session of the ``sum'' program} \label{debug-gdb}

\input{appendices/gdb_listing.tex}

\section{Ocamldebug session of the ``sum'' program} \label{debug-ocaml}

\input{appendices/ocamldebug_listing.tex}

\chapter{Project Proposal}

\input{../proposal/body}

\end{document}
